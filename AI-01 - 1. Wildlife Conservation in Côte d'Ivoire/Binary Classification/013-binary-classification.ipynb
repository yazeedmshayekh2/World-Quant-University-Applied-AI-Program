{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<p>\n",
    "  <b>AI Lab: Deep Learning for Computer Vision</b><br>\n",
    "  <b><a href=\"https://www.wqu.edu/\">WorldQuant University</a></b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  <p>\n",
    "    <center><b>Usage Guidelines</b></center>\n",
    "  </p>\n",
    "  <p>\n",
    "    This file is licensed under <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International</a>.\n",
    "  </p>\n",
    "  <p>\n",
    "    You <b>can</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Download this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Post this file in public repositories</li>\n",
    "    </ul>\n",
    "    You <b>must always</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Give credit to <a href=\"https://www.wqu.edu/\">WorldQuant University</a> for the creation of this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Provide a <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">link to the license</a></li>\n",
    "    </ul>\n",
    "    You <b>cannot</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: red\">✗</span> Create derivatives or adaptations of this file</li>\n",
    "      <li><span style=\"color: red\">✗</span> Use this file for commercial purposes</li>\n",
    "    </ul>\n",
    "  </p>\n",
    "  <p>\n",
    "    Failure to follow these guidelines is a violation of your terms of service and could lead to your expulsion from WorldQuant University and the revocation your certificate.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like in the last lesson, there are a few things we need to do before we can begin. We'll start by importing the packages we'll need for this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchinfo\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.version import __version__ as tqdm__version__\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll print out the version numbers for our libraries, including Python. We want to make sure that anyone who reviews our work knows exactly what software we used in case they want to reproduce our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Platform:\", sys.platform)\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"---\")\n",
    "print(\"CV2 version : \", cv2.__version__)\n",
    "print(\"matplotlib version : \", matplotlib.__version__)\n",
    "print(\"numpy version : \", np.__version__)\n",
    "print(\"torch version : \", torch.__version__)\n",
    "print(\"torchinfo version : \", torchinfo.__version__)\n",
    "print(\"torchvision version : \", torchvision.__version__)\n",
    "print(\"PIL version : \", PIL.__version__)\n",
    "print(\"scikit-learn version: \", sklearn.__version__)\n",
    "print(\"tqdm version: \", tqdm__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last (this is a new step), we'll check if GPUs are available. Remember from the last lesson that GPUs allow us to build our models more quickly compared to the CPU. Some computers come with GPUs, which allow for bigger and faster model building. In PyTorch, the `cuda` package is used to access GPUs on Linux and Windows machines; `mps` is used on Macs. \n",
    "\n",
    "We'll use the `device` variable later to set the location of our data and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build a model that can identify wildlife in photos taken by automated surveillance systems, also called \"camera traps.\"\n",
    "\n",
    "We downloaded the data in the previous lesson. Here, we'll use the data in the `data_binary` folder. It's already broken up in a training set in `train`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.1:** Assign `train_dir` the path to the training data. Follow the pattern of `data_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"data_p1\", \"data_binary\")\n",
    "train_dir = ...\n",
    "\n",
    "print(\"Data Directory:\", data_dir)\n",
    "print(\"Training Data Directory:\", train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're doing binary classification, we'll have two different labels. The data for each label is separated into their own folder. The name of the folder corresponds to the name of the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(train_dir)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the names, our training data falls into two classes. We have either an image of a hog or an image where there's no animal present (`\"blank\"`). We want our model to distinguish between these two types of images. We call this task binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out how many images we have for each label. We can do so with `listdir` function, which lists the names of all files in a folder. We can then check the length of the returned list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.2:**  Determine the number of blank images in the training data and assign the result to `blank_images`. Use the code for `hog_images` as a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_path = os.path.join(train_dir, \"hog\")\n",
    "hog_images = os.listdir(hog_path)\n",
    "print(\"length of hog images: \", len(hog_images))\n",
    "\n",
    "blank_path = ...\n",
    "blank_images = ...\n",
    "print(\"length of blank images: \", ...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are more \"blank\" than \"hog\" images. This makes sense as there might be a lot of false positives where the camera goes off when no animal is in the frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the path of one image for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.3:** Display the path of one image of the blank class. We've illustrated how this is done for the hog class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_image_name = hog_images[0]\n",
    "print(hog_image_name)\n",
    "\n",
    "hog_image_path = os.path.join(hog_path, hog_image_name)\n",
    "print(hog_image_path)\n",
    "\n",
    "blank_image_name = ...\n",
    "print(blank_image_name)\n",
    "\n",
    "blank_image_path = ...\n",
    "print(blank_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Recall how the mode describes the pixel data of the images. In the past, we've seen both grayscale and red green blue (RGB). It's also important to check out the size of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.4:** Print out the mode and size for the blank image sample. We've shown how this is done for the hog sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_img_pil = Image.open(hog_image_path)\n",
    "print(\"Hog image: \", hog_img_pil.mode, hog_img_pil.size)\n",
    "\n",
    "blank_img_pil = ...\n",
    "print(\"Blank image: \", ..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see each image using the Pillow package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_img_pil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see the hog? We see something in the frame that could possibly be an animal. At least it'll take us some time to decide if it's really a hog. We're starting to see the advantage of having a computer identify if there's a hog in the image. A human manually reviewing images may have missed the hog, especially if they're going through the images quickly. Of course, we need to actually build a system that will perform well and identify images where the hog can be easily missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_img_pil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't appear to be a hog in this image. A computer can quickly return whether the image is blank but a human may spend several seconds or even longer to make sure there's no hog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure all of our images are in the same mode. We want to make sure they're in RGB format. If not, we'll need to convert them. In fact, our sample hog image was in grayscale, denoted by the \"L\" for its mode value. We'll create a custom transformer that will convert an image to RGB mode if it's not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToRGB:\n",
    "    def __call__(self, img):\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the special method `__call__` which makes it a callable class. In other words, it acts like a function. We need this method to use `ConvertToRGB` in our preprocessing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember how we previously used utilities from the `torchvision` package. We'll use `transforms.Compose` to create a \"pipeline\" of preprocessing sets. The steps defined (in order) will be:\n",
    "\n",
    "* Convert image (if needed) to RGB\n",
    "* Resize the image\n",
    "* Convert the images to PyTorch tensors\n",
    "\n",
    "Afterwards, we'll load the data and apply the transformation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.5:** Add the missing last step where we convert images to PyTorch tensors. In a previous lesson we used `transform.ToTensor` to accomplish the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation to apply to the images\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        ConvertToRGB(),  # Convert images to RGB format if not already\n",
    "        transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "        # Convert images to tensors\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(type(transform))\n",
    "print(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "You might be wondering why we need to resize the images. Unfortunately, the images are not all the same shape.  You might have remembered how the two sample images we looked at were different shapes. We saw this when we opened the images in the notebook. Inconsistent image dimensions is common when we gather data from various sources. For deep learning, we need a lot of data so we can't be too picky and remove data that differ in shape. The solution to the inconsistent shape is convert all images to a standard size.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the data by using `datasets` from the `torchvision` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using `ImageFolder`\n",
    "dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dataset` object has the attribute `.classes` which returns a list of distinct classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.imgs` attribute is a list of tuples of path to image and label. The label value will be a number. Since we're doing binary classification, there will only be two distinct numbers. Those numbers are 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.6:** Prove that the only distinct values of `im` are `0` and `1`. You should use a `set` data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = dataset.imgs\n",
    "print(im[0])\n",
    "\n",
    "distinct_classes = ...\n",
    "print(distinct_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we're doing supervised machine learning, we need to perform a train/validation split. A validation set is used to help choose our model when training. \n",
    "\n",
    "It's typical to use an 80/20 split. The `random_split` function will help us perform the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important, don't change this!\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2], generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect the sizes of the splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.7:**  Print out the length of the validation dataset. We've done so for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of training set: {len(train_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good to explore the data. We'll create a visualization to show the breakdown of the two classes. The function below goes through the dataset and counts how many images are in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(dataset):\n",
    "    c = Counter(x[1] for x in tqdm(dataset))\n",
    "    class_to_index = dataset.dataset.class_to_idx\n",
    "    return pd.Series({cat: c[idx] for cat, idx in class_to_index.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = class_counts(train_dataset)\n",
    "train_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas built-in plotting can make a nice visualization out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts.sort_values().plot(kind=\"bar\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.8:** Use the function and pandas to make the same plot for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_counts = ...\n",
    "\n",
    "# Make a bar chart from the function output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From both visualizations, we see two things:\n",
    "* About two-thirds of the data is the \"blank\" label.\n",
    "* Both the training and validation set are similarly distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're closer to training a model. The next step is to create `DataLoader` objects. These objects are iterables that work well with PyTorch when training. We'll use a batch size of 32, which is standard for neural networks. The main difference between the `DataLoader` for training and validation is that shuffling is turned on for training. Turning on shuffling for the training data randomly rearranges the data after we have gone over all of the batches. Shuffling prevents any particular batch of data from having too much influence on the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.9:** Create the validation loader. Make sure to set shuffling to be off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# Important, don't change this!\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=g)\n",
    "\n",
    "val_loader = ...\n",
    "\n",
    "print(type(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the `DataLoader` objects, we'll show they're iterables by using `iter` and `next`. There's no need to do this all the time, we're just exploring how PyTorch will make use of the `DataLoader` objects. `iter` returns an _iterator_. This iterator will give us the _next_ value in an iteration.\n",
    "\n",
    "We'll get one sample batch of images and labels and make sure the dimensions match what we expect. One batch of images should be a 4D tensor with dimension `[32, 3, 224, 224]`. This is because we set the batch to 32, we have RGB images that have 3 color channels, and our images have height 224 and width 224. \n",
    "\n",
    "One batch of labels should be a one dimensional tensor of length 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.10:** Print the shape of a batch of images and the shape of a batch of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# This gives you [batch_size, channels, height, width] for images\n",
    "image_shape = ...\n",
    "print(\"Shape of batch of images\", image_shape)\n",
    "\n",
    "# This gives you [batch_size] for labels\n",
    "label_shape = ...\n",
    "print(\"Shape of batch of labels:\", label_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the `labels` tensor to make sure it's nothing but ones and zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Shallow Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to create our first neural network model. The model will be a shallow fully connected network. It'll not have too many layers, in fact, it'll have four. Here's the architecture:\n",
    "- The input layer\n",
    "- Two hidden layers\n",
    "- The output layer\n",
    "\n",
    "The image below is an example of our architecture. Note, the image shows fewer neurons than what we'll build as it's hard to visualize a model with many neurons. The important part is that we have an input layer, two hidden layers, and two nodes for the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./full_nn_two_hidden_layers.png\" alt=\"Shallow neural network with two hidden layers\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input data are images. Each image is a 3D tensor. The shape is 3 x 224 x 224. But there's one problem. This neural network can't accept images in two dimensions. We need to first _flatten_ the image. As you can imagine, we lose some information when we flatten the image. In a later lesson, we'll see a better neural network architecture at preserving the spatial relational data that is lost when flattening.\n",
    "\n",
    "Let's walk through the flattening process with `images`. Convenient for us, `images` is already a PyTorch tensor. In the previous task, we determined that its shape is $32 \\times 3 \\times 224 \\times 224$. The first dimension represents the number of images we have in the batch. If we flatten our images, we should get a tensor of 32 x 150528. Why 150528? It's the product of $3 \\times 224 \\times 224$. Each image, instead of being three dimensional, will now just have one dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.11:** Flatten the image and print out the resulting shape of the tensor. Use the `nn.Flatten` class to flatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = nn.Flatten()\n",
    "tensor_flatten = flatten(images)\n",
    "\n",
    "# Print the shape of the flattened tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening the images is the first step or layer of our model. However, it'll be tedious if we have to manually apply all the layers of our network. Instead we'll use the `nn.Sequential` class from PyTorch.  It offers an easy way to define the architecture.  As the name suggests, this class takes a sequence of layers and runs the data through them in order.  The following cell mostly defines the model, but we intentionally left out the output layer for now. We will add it later in the next task (discussed below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size from our transformer\n",
    "height = 224\n",
    "width = 224\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * height * width, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "print(\"model type:\", type(model))\n",
    "print(\"model structure:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the last layer needed for the model. That layer is a `nn.Linear` with an input size of 128 and an output size of 2. Additional layers can be added/appended to a model with `model.append`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.12:** Create the output layer. The last line of the cell below will append it to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = ...\n",
    "model.append(output_layer)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see three different types of layers being used:\n",
    "- `nn.Flatten` flattens the three-dimensional input tensors to the one-dimensional tensors that the next layers expect.\n",
    "- `nn.Linear` is a standard dense, or fully-connected, layer.  It takes two arguments, the number of inputs coming into this layer and the number of outputs produced by this layer.\n",
    "- `nn.ReLU` performs the _rectified linear unit_ activation.  Activation functions are necessary for neural networks to work, and ReLU is a popular choice.\n",
    "\n",
    "The last `nn.Linear` is our output layer.  It must have 128 inputs, to match the output of the preceding layer, and it must have 2 outputs to match the two classes. Note that there's no activation function applied after the output layer.  This means that the outputs of this layer are the _logits_.  Later on, these logits will be the input to a normalization function, called softmax in this case, that will turn the logits into probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will run much more quickly on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.13:**  Use `model.to` function to place the model on `device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(...)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The output of the previous cell outlines our architecture. We can get a more detailed look with the `summary` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(batch_size, 3, height, width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several things to notice from above:\n",
    "* how many parameters we have for each layer\n",
    "* how many multiplication and addition operations we're going to perform\n",
    "* the total size of our model\n",
    "\n",
    "Even for a shallow network of just two hidden layers we have over 77 million parameters. This number far exceeds anything you may have worked with in machine learning models that aren't neural networks. You can begin to see why we need to use a specialized package for building and training neural network models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several pieces we need beyond the model object. First, we need to define a loss function. The loss function measures how well our model does for a given set of model parameters. The chosen loss function, cross-entropy, is pretty standard. It's the same loss function used for simpler machine learning models such as logistic regression.  Note that this function expects the input to be logits from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need an optimizer.  This will adjust the model's parameters to try to minimize the loss function.  We've chosen the Adam optimizer, a popular optimizer. The Adam optimizer is a gradient based optimizer like stochastic gradient descent. The Adam optimizer has additional features that make it less likely to get stuck in a local minimum. It converges to a better state faster than standard stochastic gradient descent. The `optim.Adam` class is initialized with the model parameters through `model.parameters`. An optional argument is the learning rate `lr`. This controls how large the step sizes are in gradient descent. Keeping the default value will be fine for our purposes. We've explicitly specified the default value in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create a function called `train_epoch` that encapsulates the training process. The code is daunting at first but we're going to break it down. The function accepts\n",
    "- `model`: The PyTorch model we built with a specific architecture\n",
    "- `optimizer`: The optimizer that will be used to best adjust the model weights\n",
    "- `loss_fn`: The loss function that the optimizer is trying to minimize\n",
    "- `data_loader`: The `DataLoader` object for the training dataset that makes it easy to iterate over batches\n",
    "- `device`: The device where we're going to place the tensors\n",
    "\n",
    "The function returns the average loss function on the training data over the entire epoch.  Later, we'll use this to see if the model is making progress in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loss_fn, data_loader, device=\"cpu\"):\n",
    "    # We'll report the loss function's average value at the end of the epoch.\n",
    "    training_loss = 0.0\n",
    "\n",
    "    # The train method simply sets the model in training mode. No training\n",
    "    # has happened.\n",
    "    model.train()\n",
    "\n",
    "    # We iterate over all batches in the training set to complete one epoch\n",
    "    for inputs, targets in tqdm(data_loader, desc=\"Training\", leave=False):\n",
    "        # Sets the gradients to zero. We need to do this every time.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Unpack images (X) and labels (y) from the batch and add those\n",
    "        # tensors to the specified device.\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # We make a forward pass through the network and obtain the logits.\n",
    "        # With the logits, we can calculate our loss.\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        # After calculating our loss, we calculate the numerical value of\n",
    "        # the derivative of our loss function with respect to all the\n",
    "        # trainable model weights. Once we have the gradients calculated,\n",
    "        # we let the optimizer take a \"step\", in other words, update or\n",
    "        # adjust the model weights.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # We increment the training loss for the current batch\n",
    "        training_loss += loss.data.item() * inputs.size(0)\n",
    "\n",
    "    # We calculate the training loss over the completed epoch\n",
    "    return training_loss / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "The <code>tqdm</code> function that is wrapped around the <code>data_loader</code> will give us a progress bar that fills up as we process the data.  It's not necessary for the training process.  It's just there to reassure us that something is actually happening!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train the model for one epoch. The `train_epoch` function returns the average training loss, cross-entropy, for the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value = train_epoch(model, optimizer, loss_fn, train_loader, device)\n",
    "print(f\"The average loss during the training epoch was {loss_value:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice feature of neural networks is that when we do another training run, it doesn't start training from scratch. In other words, training resumes from the current weights and continues to adjust the weights to improve the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn to train the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.14:** Train the model using a single epoch with the *training data*. Print out the model's loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value = ...\n",
    "print(f\"The average loss during the training epoch was {loss_value:.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function we're using in this problem, the cross-entropy, is difficult for humans to interpret.  We know that lower is better, but is that number good or bad?  To help us humans judge, we'll calculate the accuracy of the model, the fraction of predictions it gets right.  To do that, we need the model to make predictions.\n",
    "\n",
    "The following function will make a prediction for each row of data in `data_loader`, using `model`.  As with the `train_epoch` function above, it's a bit daunting.  The comments explain what each section does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader, device=\"cpu\"):\n",
    "    # This tensor will store all of the predictions.\n",
    "    all_probs = torch.tensor([]).to(device)\n",
    "\n",
    "    # We set the model to evaluation mode. This mode is the opposite of\n",
    "    # train mode we set in the train_epoch function.\n",
    "    model.eval()\n",
    "\n",
    "    # Since we're not training, we don't need any gradient calculations.\n",
    "    # This tells PyTorch not to calculate any gradients, which speeds up\n",
    "    # some calculations.\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Again, we iterate over the batches in the data loader and feed\n",
    "        # them into the model for the forward pass.\n",
    "        for inputs, targets in tqdm(data_loader, desc=\"Predicting\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "\n",
    "            # The model produces the logits.  This softmax function turns the\n",
    "            # logits into probabilities.  These probabilities are concatenated\n",
    "            # into the `all_probs` tensor.\n",
    "            probs = F.softmax(output, dim=1)\n",
    "            all_probs = torch.cat((all_probs, probs), dim=0)\n",
    "\n",
    "    return all_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll demo using the function above with the *training data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_train = predict(model, train_loader, device)\n",
    "print(probabilities_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dimension of this tensor is the same as the size of our data set because it has made a prediction for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.15:** Make a prediction for each row of the *validation data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_val = ...\n",
    "print(probabilities_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the predictions that `predict` returned? Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(probabilities_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see two numbers here.  The first is the probability that this image is of the first class (\"blank\") and the second is the probability that it's of the second class (\"hog\"). Because these are the only two possibilities, they should add up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_train[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.16:** Print out the prediction for the first row of the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the probabilities of the first row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.17:** Sum the probabilities to show that they indeed sum to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_probability = ...\n",
    "print(f\"Sum of probabilities: {total_probability.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a prediction from these probabilities, we predict the class with the highest probability for each row.  This can be done with the `torch.argmax` function, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = torch.argmax(probabilities_train, dim=1)\n",
    "\n",
    "print(f\"Predictions shape: {predictions_train.shape}\")\n",
    "print(f\"First 10 predictions: {predictions_train[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.18:** Predict the most likely class label using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_val = ...\n",
    "\n",
    "print(f\"Predictions shape: {predictions_val.shape}\")\n",
    "print(f\"First 10 predictions: {predictions_val[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll compare the training set predictions to the actual class labels for the training set. The `torch.eq` function will help with this. We'll find the fraction that are correct. This is the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_train = torch.cat([labels for _, labels in train_loader]).to(device)\n",
    "is_correct_train = torch.eq(predictions_train, targets_train)\n",
    "total_correct_train = torch.sum(is_correct_train).item()\n",
    "accuracy_train = total_correct_train / len(train_loader.dataset)\n",
    "\n",
    "print(f\"Accuracy on the training data: {accuracy_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.19:**  Calculate the accuracy of the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_val = ...\n",
    "is_correct_val = ...\n",
    "total_correct_val = ...\n",
    "accuracy_val = ...\n",
    "\n",
    "print(f\"Accuracy on the validation data: {accuracy_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a lot of work we did to get the accuracy. It's more efficient to do this calculation batch by batch. It's best we wrap that code into a function. The `score` function, below, does just that. It's very similar to the prediction function, but instead of gathering all the predictions, it just calculates the number of correct predictions in each batch.  It also calculates the loss function over the whole batch. We'll use this to compare the loss function value on the training set and the validation set, to understand if there's any overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, data_loader, loss_fn, device=\"cpu\"):\n",
    "    # Initialize the total loss (cross entropy) and the number of correct\n",
    "    # predictions. We'll increment these values as we loop through the\n",
    "    # data.\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    # We set the model to evaluation mode. This mode is the opposite of\n",
    "    # train mode we set in the train_epoch function.\n",
    "    model.eval()\n",
    "\n",
    "    # Since we're not training, we don't need any gradient calculations.\n",
    "    # This tells PyTorch not to calculate any gradients, which speeds up\n",
    "    # some calculations.\n",
    "    with torch.no_grad():\n",
    "        # We iterate over the batches in the data loader and feed\n",
    "        # them into the model for the forward pass.\n",
    "        for inputs, targets in tqdm(data_loader, desc=\"Scoring\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "\n",
    "            # Calculating the loss function for this batch\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output, targets)\n",
    "            total_loss += loss.data.item() * inputs.size(0)\n",
    "\n",
    "            # Calculating the correct predictions for this batch\n",
    "            correct = torch.eq(torch.argmax(output, dim=1), targets)\n",
    "            total_correct += torch.sum(correct).item()\n",
    "\n",
    "    return total_loss / len(data_loader.dataset), total_correct / len(\n",
    "        data_loader.dataset\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we show how easy it's to use the `score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train, accuracy_train = score(model, train_loader, loss_fn, device)\n",
    "print(f\"Training accuracy from score function: {accuracy_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.20:** Use the `score` function on the validation data, and check that we get the same accuracy as we computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val, accuracy_val = ...\n",
    "print(f\"Validation accuracy from score function: {accuracy_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the pieces we need for our training loop.  This loop will run over a number of epochs, calling the `train_epoch` function and the `score` function, and printing out some diagnostic information so we can see how the training is going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Run train_epoch once, and capture the training loss.\n",
    "        training_loss = train_epoch(model, optimizer, loss_fn, train_loader, device)\n",
    "\n",
    "        # Score the model on the validation data.\n",
    "        validation_loss, validation_accuracy = score(model, val_loader, loss_fn, device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch}, Training Loss: {training_loss:.2f}, \"\n",
    "            f\"Validation Loss: {validation_loss:.2f}, Validation Accuracy: {validation_accuracy:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\"> <strong>Regarding Model Training Times</strong>\n",
    "\n",
    "In the next few cells you'll experience training a Deep Learning model for the first time. Training models is computationally intensive and can be very time-consuming. The particular model we're dealing with in this notebook is small enough that training takes less than 5 minutes.\n",
    "\n",
    "But in further lessons, training times could last well over one hour.\n",
    "\n",
    "To streamline your learning experience, we are including pre-trained models that you can just load and use without the need to sit and wait for training to finish. The cells to load the model are purposely marked, so you won't miss them.\n",
    "\n",
    "You are free to experience training the models by yourself, <strong>but make sure you load the pre-trained model before continuing, as the graded tasks will depend on this particular model</strong>.\n",
    "\n",
    "Also, are you curious how we have saved the trained model? It'll be explained in detail at the end of this lesson.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the function for training, let's use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training loss goes down and the accuracy goes up after each epoch. Can we do better? Let's try. Recall how a nice feature of neural networks is that we can pause and continue training without having to start from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.21:** Continue training the model for two more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many epochs should we train for? To answer that question, we need to balance between underfitting and overfitting. For now, we can train for more epochs until we observe the validation score is not improving or is actually getting worse. In future projects, we'll create a visualization called a learning curve to help us decide the correct number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<strong>Make sure that you load the pre-trained model running the cell below.</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-trained model with the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model/trained_model.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with our model trained we want to see how well it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3.22:** Make a prediction for each image in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities_val = ...\n",
    "predictions_val = ...\n",
    "print(predictions_val[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy only gives us a simplified view of how well the model performed. We'd like to see how many of the mistakes were from predicting a hog when it's really not a hog, and vice versus. In short, we want a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(targets_val.cpu(), predictions_val.cpu())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"blank\", \"hog\"])\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=\"vertical\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "69% of our validation data is the blank class. If our errors are proportionally distributed, we should expect about 69% of our errors to be when we predict \"blank\" instead of hog. Are the errors uniformly distributed?\n",
    "\n",
    "Let's run our model on one chosen image of a hog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(data_dir, \"train/hog/ZJ000072.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as JupyterImage\n",
    "JupyterImage(filename=img_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"blank\", \"hog\"]\n",
    "\n",
    "img = Image.open(os.path.join(data_dir, \"train/hog/ZJ000072.jpg\"))\n",
    "img = transform(img).to(device)\n",
    "img = torch.unsqueeze(img, 0)\n",
    "\n",
    "model.eval()\n",
    "prediction = F.softmax(model(img), dim=1)\n",
    "prediction = prediction.argmax()\n",
    "print(labels[prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model predicted correctly! But how confident was it's prediction? Neural networks are probabilistic classifiers. The probabilities are obtained by running the model outputs through the softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(model(img), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our model determines that the probability the image shows a hog is much greater than 50%. It's fairly confident that it's correct. These probabilities are useful as they can help us decide whether we should take any action based on the model's prediction. For example, if images are being collected and analyzed in real time, we may only want to alert conservation staff if we're really confident we have spotted a hog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "The training process relies on randomness. There are various sources for this randomness. For example, we shuffle the training data after each epoch. Because of randomness, we're not going to get the same results every time. As a consequence, some results we discuss in the text might be different from what you get when running the notebook. If your results are very different, you should restart the notebook and rerun the cells. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Models\n",
    "We can either save the entire model using `save` or just the parameters using `state_dict`. Using the latter is normally preferable, as it allows you to reuse parameters even if the model's structure changes (or apply parameters from one model to another). Saving the model avoids having to retrain the model the next time we want to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, os.path.join(\"model\", \"shallownet\"))\n",
    "model = torch.load(os.path.join(\"model\", \"shallownet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(\"model\", \"shallownet\"))\n",
    "new_model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(3 * height * width, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 2),\n",
    ")\n",
    "model_state_dict = torch.load(os.path.join(\"model\", \"shallownet\"))\n",
    "new_model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work for making it to the end! There was a lot of new concepts and ideas in this notebook. We also built our very first neural network model. Here are the key ideas from this notebook:\n",
    "\n",
    "* Our data often needs to be preprocessed. In our case, we had to resize to a standard size and make sure all images were in RGB mode. `transform.Compose` made it easy to define a preprocessing pipeline.\n",
    "* The fully connected model is made up of layers where the output of one layer is fully connected to all nodes in the next layer.\n",
    "* We used `nn.Sequential` to easily build our model's architecture by defining the order of the layers.\n",
    "* Training involves iterating through the training set. One pass through the data is called an epoch. An optimizer uses a loss function to determine how to best adjust a model's weights.\n",
    "\n",
    "In the next notebook, we'll move from binary classification to multiclass classification. We'll also build a neural network using an architecture that's more effective for image classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "This file &#169; 2024 by [WorldQuant University](https://www.wqu.edu/) is licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
